{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import arviz as av\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from threeML import (\n",
    "    DataList,\n",
    "    JointLikelihood,\n",
    "    display_spectrum_model_counts,\n",
    "    update_logging_level,\n",
    ")\n",
    "update_logging_level(\"FATAL\")\n",
    "from astromodels import Cutoff_powerlaw, Model, PointSource\n",
    "from cosmogrb.universe.survey import Survey\n",
    "\n",
    "parent_dir = os.path.abspath(\"..\")\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from zusammen import AnalysisBuilder, DataSet\n",
    "from zusammen.spectral_plot import display_posterior_model_counts\n",
    "from zusammen.stan_models.stan_model import get_model\n",
    "from cpl_prime import Cutoff_powerlaw_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the survey and process the GRBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "survey = Survey.from_file('data/survey.h5')\n",
    "ab = AnalysisBuilder(survey, use_bb=True, intervals_min=5, sig_min=10, all_above_limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.write_yaml(\"test_proc.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = DataSet.from_yaml(\"test_proc.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.to_hdf5_file(\"sgrb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet.from_hdf5_file('sgrb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.to_stan_dict()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arviz = {i: data[i] for i in (\"grb_id\", \"observed_counts\", \"response\", \"z\", \"dl\")}\n",
    "data_arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxl = []\n",
    "for i,j in enumerate(ds.to_stan_dict()[\"observed_counts\"]):\n",
    "    maxl.append(j.max())\n",
    "    print(i, j.max())\n",
    "\n",
    "print(max(maxl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "i,j = 0,0\n",
    "plt.plot(ds.to_stan_dict()[\"response\"][i,j].T @ ds.to_stan_dict()['observed_counts'][i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Stan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_model(\"cpl_simple_chunked_gc_relaxed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.clean_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.build_model(opt_exp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.to_stan_dict()\n",
    "\n",
    "n_threads = 2\n",
    "n_chains = 2\n",
    "n_warmup = 1000\n",
    "n_sampling = 500\n",
    "\n",
    "fit = m.model.sample(\n",
    "    data=data,\n",
    "    chains=n_chains,\n",
    "    parallel_chains=n_chains,\n",
    "    threads_per_chain=n_threads,\n",
    "    inits= {\n",
    "        'alpha': -1 * np.ones(data['N_intervals']),\n",
    "        'log_ec': 2 * np.ones(data['N_intervals']),\n",
    "\n",
    "        # 'log_energy_flux': -7 * np.ones(data['N_intervals']),\n",
    "        # 'log_K': -1 * np.ones(data['N_intervals']),\n",
    "\n",
    "        # 'log_energy_flux_mu_raw': 0,\n",
    "        # 'log_energy_flux_sigma': 1,\n",
    "        # 'log_energy_flux_raw': np.zeros(data['N_intervals']),\n",
    "\n",
    "        'gamma_sig_meta': 1,\n",
    "        'log_Nrest_sig_meta': 1,\n",
    "        'gamma_mu_meta': 1.5,\n",
    "        'log_Nrest_mu_meta': 52,\n",
    "        'gamma': 1.5 * np.ones(data['N_grbs']),\n",
    "        'log_Nrest': 52 * np.ones(data['N_grbs']),\n",
    "    },  # type: ignore\n",
    "    # seed=1234,\n",
    "    iter_warmup=n_warmup,\n",
    "    iter_sampling=n_sampling,\n",
    "    # max_treedepth=12,\n",
    "    # adapt_delta=0.99,\n",
    "    # step_size=0.1,\n",
    "    show_progress=True,\n",
    "    # show_console=True,\n",
    "    refresh=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.diagnose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Stan results into arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = av.from_cmdstanpy(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.add_groups(observed_data=data_arviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_netcdf(\"inference_data/testing_gc_relaxed_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = av.from_netcdf(\"inference_data/testing_gc_relaxed.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sample_stats.tree_depth.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "av.plot_trace(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "for i in range(data['N_intervals']):\n",
    "    av.plot_trace(res, var_names=[\"ec\"], coords={\"ec_dim_0\": i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "av.plot_pair(res, divergences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = res.sample_stats.diverging.stack(sample=(\"chain\", \"draw\")).values\n",
    "div.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.posterior.gamma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_intervals = res.posterior.alpha.shape[2]\n",
    "N_grbs = res.posterior.gamma.shape[2]\n",
    "length = res.posterior.gamma.shape[0] * res.posterior.gamma.shape[1]\n",
    "\n",
    "alpha = np.zeros((N_intervals, length))\n",
    "log_ec = np.zeros((N_intervals, length))\n",
    "K_prime = np.zeros((N_intervals, length))\n",
    "K= np.zeros((N_intervals, length))\n",
    "log_energy_flux = np.zeros((N_intervals, length))\n",
    "log_epeak = np.zeros((N_intervals, length))\n",
    "gamma = np.zeros((N_grbs, length))\n",
    "log_Nrest = np.zeros((N_grbs, length))\n",
    "div = np.zeros((N_intervals, length))\n",
    "samples = np.zeros((N_intervals, 3, length))\n",
    "dl = []\n",
    "\n",
    "for id in range(N_intervals):\n",
    "    alpha[id] = res.posterior.alpha.stack(sample=(\"chain\", \"draw\")).values[id]\n",
    "\n",
    "    log_ec[id] = res.posterior.log_ec.stack(sample=(\"chain\", \"draw\")).values[id]\n",
    "    K_prime[id] = res.posterior.K.stack(sample=(\"chain\", \"draw\")).values[id]\n",
    "    K[id] = (10**log_ec[id])**(-alpha[id])\n",
    "\n",
    "    log_epeak[id] = res.posterior.log_epeak.stack(sample=(\"chain\", \"draw\")).values[id]\n",
    "    log_energy_flux[id] = res.posterior.log_energy_flux.stack(sample=(\"chain\", \"draw\")).values[id]\n",
    "\n",
    "    div[id] = res.sample_stats.diverging.stack(sample=(\"chain\", \"draw\")).values\n",
    "\n",
    "    samples[id] = np.vstack((K_prime[id], alpha[id], 10.**log_ec[id]))\n",
    "\n",
    "    dl.append(ds.get_data_list_of_interval(id))\n",
    "\n",
    "# log_epeak = np.log10(2 + alpha) + log_ec\n",
    "\n",
    "for id in range(N_grbs):\n",
    "    gamma[id] = res.posterior.gamma.stack(sample=(\"chain\", \"draw\")).values[id]\n",
    "    log_Nrest[id] = res.posterior.log_Nrest.stack(sample=(\"chain\", \"draw\")).values[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(log_Nrest,1), np.mean(gamma,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = Cutoff_powerlaw_prime()\n",
    "\n",
    "bc.index.bounds = (None, None)\n",
    "bc.K.bounds = (None, None)\n",
    "bc.xc.bounds = (None, None)\n",
    "\n",
    "model = Model(PointSource(\"ps\",0,0, spectral_shape=bc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.scatter(log_ec, alpha, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "plt.scatter(K, alpha, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "for id in range(1):#range(data[\"N_intervals\"]):\n",
    "    display_posterior_model_counts(\n",
    "        dl[id][1], model, samples[id].T[::20], min_rate=1e-99\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(log_epeak, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def gc_log(log_epeak, log_Nrest, gamma, z, dl):\n",
    "    return log_Nrest - (1.099 + 2 * np.log10(dl)) + gamma * (np.log10(1 + z) + log_epeak - 2)\n",
    "\n",
    "plt.scatter(np.mean(log_epeak, 1), np.mean(log_energy_flux,1))\n",
    "log_epeak_sort = np.linspace(0.5,3)\n",
    "z = [data[\"z\"][0]] + [j for i,j in zip(data[\"z\"], data[\"z\"][1:]) if i != j]\n",
    "d_l = [data[\"dl\"][0]] + [j for i,j in zip(data[\"dl\"], data[\"dl\"][1:]) if i != j]\n",
    "for i in range(data[\"N_grbs\"]):\n",
    "    plt.plot(log_epeak_sort, gc_log(log_epeak_sort, 52, 1.5, z[i], d_l[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpl = Cutoff_powerlaw(piv=1,K=1e-1,xc=200)\n",
    "\n",
    "\n",
    "model = Model(PointSource(\"ps\",0,0, spectral_shape=cpl))\n",
    "\n",
    "ba = JointLikelihood(model,DataList(*dl[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.bayes_mvs(gamma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**log_energy_flux[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.results.get_flux(10*u.keV, 10e4*u.keV)[\"flux\"][0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_spectrum_model_counts(ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_3ml, epeak_3ml = np.zeros(data[\"N_intervals\"]), np.zeros(data[\"N_intervals\"])\n",
    "\n",
    "cpl = Cutoff_powerlaw(piv=100,K=1e-1,xc=200)\n",
    "model = Model(PointSource(\"ps\",0,0, spectral_shape=cpl))\n",
    "\n",
    "for i in range(data[\"N_intervals\"]):\n",
    "    dl = ds.get_data_list_of_interval(i)\n",
    "    ba = JointLikelihood(model,DataList(*dl))\n",
    "    ba.fit()\n",
    "    ec_3ml = ba.results.get_data_frame()[\"value\"][\"ps.spectrum.main.Cutoff_powerlaw.xc\"]\n",
    "    alpha_3ml = ba.results.get_data_frame()[\"value\"][\"ps.spectrum.main.Cutoff_powerlaw.index\"]\n",
    "    epeak_3ml[i] = (2 + alpha_3ml) * ec_3ml\n",
    "    F_3ml[i] = ba.results.get_flux(10*u.keV, 10e4*u.keV)[\"flux\"][0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epeak_mean = np.array([10**(i.mean()) for i in log_epeak])\n",
    "F_mean = np.array([10**(i.mean()) for i in log_energy_flux])\n",
    "epeak_mean, F_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epeak_3ml, F_3ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "def gc(epeak, Nrest, gamma, z, dl):\n",
    "    return Nrest / ( 4 * np.pi * dl * dl) * (epeak * (1 + z) / 100)**gamma\n",
    "\n",
    "plt.scatter(epeak_3ml, F_3ml)\n",
    "\n",
    "x = np.linspace(1,1000)\n",
    "z = [data[\"z\"][0]] + [j for i,j in zip(data[\"z\"], data[\"z\"][1:]) if i != j]\n",
    "d_l = [data[\"dl\"][0]] + [j for i,j in zip(data[\"dl\"], data[\"dl\"][1:]) if i != j]\n",
    "for zi, dli in zip(z,d_l):\n",
    "    plt.plot(x, gc(x, 1e52, 1.5, zi, dli))\n",
    "\n",
    "plt.scatter(10**(np.mean(log_epeak,1)), 10**(np.mean(log_energy_flux,1)))\n",
    "\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "av.plot_kde(log_epeak, log_energy_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "for i in gamma:\n",
    "    av.plot_kde(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "av.plot_kde(log_Nrest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, j in av.rhat(res).items():\n",
    "    print((np.array(j) - np.ones(len(j))).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor",
   "language": "python",
   "name": "bachelor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c32814d9e11908585ccc181cca6c7dae7bdf3e835febbae23bde3821f1e724f7"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
